# Carlo Revoredo

Quality Assurance (QA) | Foco em Inteligência Artificial

## Descrição

Profissional de Quality Assurance altamente experiente, com sólida formação acadêmica em Inteligência Artificial (Mestrado e Doutorado). Possui expertise em garantir a qualidade de sistemas complexos, incluindo aplicações de IA e Machine Learning, através de metodologias de teste inovadoras e análise rigorosa.

## Área de Atuação

- Quality Assurance (QA)
- Testes de Software (Manual e Automatizado)
- Testes de Sistemas de Inteligência Artificial e Machine Learning
- Avaliação de Modelos de IA
- Planejamento e Estratégia de Testes
- Automação de Testes (com foco em IA)
- Análise de Dados para Testes
- Melhoria de Processos de QA

## Experiência

- **Especialista em QA e Testes de IA** - Empresa Líder em Tecnologia (2022 - Presente)
  - Responsável pela definição da estratégia de testes e garantia de qualidade para produtos e serviços baseados em Inteligência Artificial.
  - Desenvolvimento e implementação de metodologias de teste específicas para avaliar a performance, robustez e confiabilidade de modelos de Machine Learning.
  - Criação e execução de planos de teste abrangentes, incluindo testes de conceito, integração, sistema e aceitação.
  - Liderança de equipes de teste, incluindo a implementação de automação de testes focada em cenários de IA.
  - Colaboração com cientistas de dados e engenheiros de IA para identificar e mitigar riscos de qualidade.
- **Analista de QA Sênior** - Empresa Inovadora em Soluções de Software (2018 - 2022)
  - Planejamento, execução e automação de testes funcionais, não funcionais e de regressão para diversos projetos de software.
  - Desenvolvimento de frameworks de automação de testes utilizando ferramentas como Selenium e Python.
  - Identificação, documentação e acompanhamento de defeitos, utilizando ferramentas de gerenciamento de bugs como Jira.
  - Participação ativa na melhoria contínua dos processos de QA e desenvolvimento de software.

## Formação

- **Doutorado em Ciência da Computação (com foco em Inteligência Artificial)** - Universidade Federal de Pernambuco (2024)
  - Tese: [Título da Tese, se relevante e conciso, ex: "Metodologia para Teste de Robustez em Modelos de Deep Learning"]
- **Mestrado em Ciência da Computação (com foco em Inteligência Artificial)** - Universidade Federal de Pernambuco (2022)
  - Dissertação: [Título da Dissertação, se relevante e conciso, ex: "Framework para Avaliação da Explicabilidade em Sistemas de IA"]
- **Bacharel em Ciência da Computação** - Universidade [Nome da Universidade] (2014 - 2018)

## Principais Ferramentas

- **Ferramentas de Teste:** Selenium, JUnit, TestNG, Postman, SoapUI
- **Ferramentas de Teste de IA/ML:** TensorFlow Testing, PyTest, ferramentas de avaliação de métricas de modelos (Scikit-learn, etc.)
- **Linguagens de Programação:** Python (Avançado), Java (Intermediário), JavaScript (Básico)
- **Automação de Testes:** Desenvolvimento de frameworks de automação customizados, integração com CI/CD (Jenkins, GitLab CI)
- **Gerenciamento de Bugs:** Jira, Bugzilla
- **Metodologias Ágeis:** Scrum, Kanban
- **Análise de Dados:** Pandas, NumPy

## Principais Projetos

- **Garantia de Qualidade de Plataforma de IA para Diagnóstico Médico:** Definição e execução da estratégia de testes para uma plataforma de diagnóstico médico baseada em deep learning, incluindo testes de acurácia, interpretabilidade e robustez.
- **Implementação de Framework de Testes Automatizados para Modelos de Linguagem Natural:** Desenvolvimento de um framework para automatizar testes de qualidade em modelos de linguagem natural, avaliando coerência, relevância e correção gramatical.
- **Liderança na Implementação de Testes de Performance em Sistema de Recomendação:** Responsável pela estratégia e execução de testes de performance para garantir a escalabilidade e a baixa latência de um sistema de recomendação baseado em Machine Learning.
- **Otimização do Processo de Testes em Projetos de Visão Computacional:** Implementação de novas técnicas e ferramentas para otimizar o processo de testes em projetos de visão computacional, incluindo a avaliação da precisão e da capacidade de generalização dos modelos.
